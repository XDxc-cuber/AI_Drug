{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26e840bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290893\n",
      "['s', '3', 'N', 'd', '-', 'A', '4', '5', 'e', 'C', 'P', '9', '@', '6', 'a', ')', 'B', 'F', '7', 'H', 'L', 'O', 'K', 'S', '[', '(', '8', 'l', '\\\\', '1', 'n', 'i', 'I', '/', ']', 'Z', '#', 'r', '+', 'g', '.', '=', 'M', '2', 't']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "idx_to_char = set()\n",
    "smiles = []\n",
    "\n",
    "with open('sars_protease.tsv') as f:\n",
    "    data = f.readlines()\n",
    "    for row in data[1:]:\n",
    "        smile = row.split('\\t')[1]\n",
    "        for c in smile:\n",
    "            idx_to_char.add(c)\n",
    "        smiles.append(smile)\n",
    "    idx_to_char = list(idx_to_char)\n",
    "    del(data)\n",
    "    \n",
    "print(len(smiles))\n",
    "print(idx_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb2b5170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'s': 0, '3': 1, 'N': 2, 'd': 3, '-': 4, 'A': 5, '4': 6, '5': 7, 'e': 8, 'C': 9, 'P': 10, '9': 11, '@': 12, '6': 13, 'a': 14, ')': 15, 'B': 16, 'F': 17, '7': 18, 'H': 19, 'L': 20, 'O': 21, 'K': 22, 'S': 23, '[': 24, '(': 25, '8': 26, 'l': 27, '\\\\': 28, '1': 29, 'n': 30, 'i': 31, 'I': 32, '/': 33, ']': 34, 'Z': 35, '#': 36, 'r': 37, '+': 38, 'g': 39, '.': 40, '=': 41, 'M': 42, '2': 43, 't': 44}\n",
      "45\n",
      "[9, 9, 21, 9, 9, 9, 2, 9, 9, 25, 41, 21, 15, 2, 9, 29, 41, 9, 9, 41, 9, 25, 9, 41, 9, 29, 15, 21, 9, 25, 17, 15, 25, 17, 15, 17, 40, 9, 27]\n"
     ]
    }
   ],
   "source": [
    "char_to_idx = dict([(c, i) for i,c in enumerate(idx_to_char)])\n",
    "char_size = len(idx_to_char)\n",
    "smiles_indices = [[char_to_idx[c] for c in smile] for smile in smiles]\n",
    "print(char_to_idx)\n",
    "print(char_size)\n",
    "print(smiles_indices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56a15ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, time, math\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import d2lzh_pytorch as d2l\n",
    "\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4ee2f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will use cpu\n"
     ]
    }
   ],
   "source": [
    "num_input, num_hiddens, num_outputs = char_size, 256, char_size\n",
    "print('will use', device)\n",
    "\n",
    "def get_params():\n",
    "    def _one(shape):\n",
    "        ts = torch.tensor(np.random.normal(0, 0.01, size=shape), device=device, dtype=torch.float32)\n",
    "        return torch.nn.Parameter(ts, requires_grad=True)\n",
    "\n",
    "    # hidden\n",
    "    W_xh = _one((num_input, num_hiddens))\n",
    "    W_hh = _one((num_hiddens, num_hiddens))\n",
    "    b_h = torch.nn.Parameter(torch.zeros(num_hiddens, device=device, requires_grad=True))\n",
    "\n",
    "    # output\n",
    "    W_hq = _one((num_hiddens, num_outputs))\n",
    "    b_q = torch.nn.Parameter(torch.zeros(num_outputs, device=device, requires_grad=True))\n",
    "    return nn.ParameterList([W_xh, W_hh, b_h, W_hq, b_q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8028285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_rnn_state(batch_size, num_hiddens, device):\n",
    "    return (torch.zeros((batch_size, num_hiddens), device=device),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72c85b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn(inputs, state, params):\n",
    "    W_xh, W_hh, b_h, W_hq, b_q = params\n",
    "    H, = state\n",
    "    outputs = []\n",
    "    for X in inputs:\n",
    "        H = torch.tanh(torch.matmul(X, W_xh) + torch.matmul(H, W_hh) + b_h)\n",
    "        Y = torch.matmul(H, W_hq) + b_q\n",
    "        outputs.append(Y)\n",
    "    return outputs, (H,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1faf935c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CCOCC', 'COCCN', 'COCCN', 'C1CCC', 'COC1=', 'CCOC(', 'CCOC(', 'CC(=O', 'CCCCO', 'CC(C(']\n"
     ]
    }
   ],
   "source": [
    "num_epochs, num_steps, batch_size, lr, clipping_theta = 2, 5, 4, 0.1, 1e-2\n",
    "pred_len = 24\n",
    "# 测试用例为所有训练的smiles的前5个字符\n",
    "prefixes = [smile[:5] for smile in smiles]\n",
    "\n",
    "print(prefixes[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c95b1bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train_and_predict_rnn(rnn, get_params, init_rnn_state, num_hiddens,\n",
    "                          vocab_size, device, corpus_indices, idx_to_char,\n",
    "                          char_to_idx, is_random_iter, num_epochs, num_steps,\n",
    "                          lr, clipping_theta, batch_size, pred_len, prefixes):\n",
    "    if is_random_iter:\n",
    "        data_iter_fn = d2l.data_iter_random\n",
    "    else:\n",
    "        data_iter_fn = d2l.data_iter_consecutive\n",
    "    params = get_params()\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        mm = 0\n",
    "        for smile in corpus_indices:\n",
    "            if not is_random_iter:\n",
    "                state = init_rnn_state(batch_size, num_hiddens, device)\n",
    "            l_sum, n, start = 0.0, 0, time.time()\n",
    "            data_iter = data_iter_fn(smile, batch_size, num_steps, device)\n",
    "            for X, Y in data_iter:\n",
    "                if is_random_iter:\n",
    "                    state = init_rnn_state(batch_size, num_hiddens, device)\n",
    "                else: \n",
    "                    for s in state:\n",
    "                        s.detach_()\n",
    "                \n",
    "                inputs = d2l.to_onehot(X, vocab_size)\n",
    "                (outputs, state) = rnn(inputs, state, params)\n",
    "                outputs = torch.cat(outputs, dim=0)\n",
    "                y = torch.transpose(Y, 0, 1).contiguous().view(-1)\n",
    "                l = loss(outputs, y.long())\n",
    "                \n",
    "                if params[0].grad is not None:\n",
    "                    for param in params:\n",
    "                        param.grad.data.zero_()\n",
    "                l.backward()\n",
    "                d2l.grad_clipping(params, clipping_theta, device)\n",
    "                d2l.sgd(params, lr, 1)\n",
    "                l_sum += l.item() * y.shape[0]\n",
    "                n += y.shape[0]\n",
    "\n",
    "            mm += 1\n",
    "            if mm % 20000 == 0:\n",
    "                print(mm, \" smiles were trained\")\n",
    "        print(\"Training has done.\")\n",
    "\n",
    "        return [d2l.predict_rnn(prefix, pred_len, rnn, params, init_rnn_state,\n",
    "                num_hiddens, vocab_size, device, idx_to_char, char_to_idx) for prefix in prefixes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1404263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000  smiles were trained\n",
      "40000  smiles were trained\n",
      "60000  smiles were trained\n",
      "80000  smiles were trained\n",
      "100000  smiles were trained\n",
      "120000  smiles were trained\n",
      "140000  smiles were trained\n",
      "160000  smiles were trained\n",
      "180000  smiles were trained\n",
      "200000  smiles were trained\n",
      "220000  smiles were trained\n",
      "240000  smiles were trained\n",
      "260000  smiles were trained\n",
      "280000  smiles were trained\n",
      "Training has done.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "ret = my_train_and_predict_rnn(rnn, get_params, init_rnn_state, num_hiddens, char_size, device, smiles_indices,\n",
    "                            idx_to_char, char_to_idx, False, num_epochs, num_steps, lr, clipping_theta, batch_size,\n",
    "                            pred_len, prefixes)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5932bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCOCC1=CC=CC=C(C=C1)C(=O)CCC(\n",
      "COCCN1CCC1=CC=CC=C(C=C1)C(=O)\n",
      "COCCN1CCC1=CC=CC=C(C=C1)C(=O)\n",
      "C1CCC(=O)NC(=O)C2=CC=CC=C(C=C\n",
      "COC1=CC=CC=C(C=C1)C(=O)CCC(=O\n",
      "CCOC(=O)CCC(=O)NC(=O)C2=CC=CC\n",
      "CCOC(=O)CCC(=O)NC(=O)C2=CC=CC\n",
      "CC(=O)NC(=O)C2=CC=CC=C(C=C1)C\n",
      "CCCCOC1=CC=CC=C(C=C1)C(=O)CCC\n",
      "CC(C(=O)NC(=O)C2=CC=CC=C(C=C1\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(ret[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8a51f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.14205910764439%\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for smile in ret:\n",
    "    if Chem.MolFromSmiles(smile) != None:\n",
    "        cnt += 1\n",
    "\n",
    "print(cnt / len(ret) * 100, end='%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ceee1aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.03535741737125%\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "    由于生成序列很难保证括号的合法性，因此加一步检验括号合法性的筛选，\n",
    "    在所有括号合法的smiles里检验正确率\n",
    "\"\"\"\n",
    "def if_bracket_legal(smile):\n",
    "    cnt = 0\n",
    "    for c in smile:\n",
    "        if c == '(':\n",
    "            cnt += 1\n",
    "        elif c == ')':\n",
    "            cnt -= 1\n",
    "        if cnt < 0:\n",
    "            return False\n",
    "    return cnt == 0\n",
    "\n",
    "cnt, all_num = 0, 0\n",
    "for smile in ret:\n",
    "    if if_bracket_legal(smile):\n",
    "        all_num += 1\n",
    "        if Chem.MolFromSmiles(smile) != None:\n",
    "            cnt += 1\n",
    "\n",
    "print(cnt / all_num * 100, end='%\\n')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "abe01e674a900eecd79a340f53a9f15d92e94e243d4c4e9335de22357bf1177a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
